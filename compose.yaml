services:
  ollama:
    #    image: ollama/ollama # Specifies the Ollama image to use
    build:
      context: . # Specifies the build context as the . directory
      dockerfile: Dockerfile_ollama # Uses the Dockerfile in the build context
      args:
        - LLM_MODEL=${LLM_MODEL}
        - EMBEDDING_MODEL=${EMBEDDING_MODEL}
    env_file:
      - .env
    container_name: ollama # Sets the container name to ollama
    ports:
      - "11434:11434" # Maps port 11434 on the host to port 11434 in the container
    environment:
      - GIN_MODE=release
    networks:
      - pubkb-network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia # Specifies the driver to use for GPU
              count: 1 # Reserves 1 GPU
              capabilities: [ gpu ] # Specifies that the device capability is GPU

  pubkb:
    build:
      context: . # Specifies the build context as the . directory
      dockerfile: Dockerfile_streamlit # Uses the Dockerfile in the build context
      args:
        - LLM_MODEL=${LLM_MODEL}
        - EMBEDDING_MODEL=${EMBEDDING_MODEL}
    env_file:
      - .env
    container_name: pubkb # Sets the container name to pubkb
    ports:
      - "8501:8501" # Maps port 8501 on the host to port 8501 in the container
    depends_on:
      - ollama # Ensures the ollama service is started before pubkb
      - redis # Ensures the redis service is started before pubkb
    stdin_open: true # docker run -i
    tty: true        # docker run -t
    networks:
      - pubkb-network

  redis:
    image: redis/redis-stack
    container_name: redis # Sets the container name to redis
    ports:
      - "6379:6379"
    networks:
      - pubkb-network

networks:
  pubkb-network:
    driver: bridge